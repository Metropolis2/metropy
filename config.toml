# Projected coordinate system to use for metric operations (e.g., computing edges' length).
# See: https://en.wikipedia.org/wiki/Projected_coordinate_system
crs = "EPSG:2154"

# Random seed to be used for random number generators.
random_seed = 13081996

# Path to the directory where graphs should be stored.
graph_directory = "./output/graph/"

# Path to METROPOLIS2 executable.
metropolis_exec = "./execs/metropolis_cli"
# Path to METROPOLIS2's routing executable.
routing_exec = "./execs/routing_cli"

# Directory to be used to temporarily store files.
tmp_directory = "./tmp/"

# Directory where the run input / output are stored.
run_directory = "./run/main"

# Path to the file where the imported edges of the road network are stored
# (possible extensions: parquet, geojson, fgb, shp).
raw_edges_file = "./output/road_network/edges_raw.parquet"
# Path to the file where the imported edges of the road network are stored after the cleaning
# process (possible extensions: parquet, geojson, fgb, shp).
clean_edges_file = "./output/road_network/edges_clean.parquet"
# Path to the file with edges' capacities.
capacities_filename = "./output/road_network/edges_capacities.parquet"

# Path to the file where the imported edges of the walking road network are stored
# (possible extensions: parquet, geojson, fgb, shp).
raw_walk_edges_file = "./output/road_network/edges_walk_raw.parquet"
# Path to the file where the imported edges of the walking road network are stored after the
# cleaning process (possible extensions: parquet, geojson, fgb, shp).
clean_walk_edges_file = "./output/road_network/edges_walk_clean.parquet"

# Path to the directory where the population files are stored.
population_directory = "./output/synthetic_population_20pct/"

[default_edge_capacities]
# Bottleneck capacity per roadtype, in PCE/h.
# motorway = 2000.0
# trunk = 2000.0
# primary = 1800.0
# secondary = 1500.0
# tertiary = 1200.0
# motorway_link = 1800.0
# trunk_link = 1800.0
# primary_link = 1800.0
# secondary_link = 1500.0
# tertiary_link = 1200.0
# living_street = 900.0
# unclassified = 1200.0
# residential = 1200.0
# #road = 300
# #service = 300
# traffic_signals_factor = 0.5
# roundabout_factor = 0.75

motorway = 1700.0
trunk = 1850.0
primary = 2150.0
secondary = 1700.0
tertiary = 1400.0
motorway_link = 1350.0
trunk_link = 1350.0
primary_link = 2150.0
secondary_link = 1700.0
tertiary_link = 1400.0
living_street = 900.0
unclassified = 1000.0
residential = 1300.0
#road = 300
#service = 300
traffic_signals_factor = 0.7
roundabout_factor = 0.4

[run]
# Directory where the run files are stored.
directory = "./run/main/"
# Format to use for the input and output files ("CSV" or "Parquet").
format = "Parquet"
# Ratio of population that is simulated.
simulation_ratio = 0.2
# Ratio of truck trips simulated.
truck_simulation_ratio = 1.0
# Simulation period.
period = [10_800, 97_200]
# Time interval between two breakpoints in the travel-time functions (in seconds).
recording_interval = 900.0
# Number of iterations to run.
nb_iterations = 50
# Value of the smoothing factor for the learning model (weight of the simulated travel times).
smoothing_factor = 0.02
# Whether spillback is enabled.
spillback = true
# Maximum amount of time (in seconds) a vehicle can be pending to enter the next edge.
max_pending_duration = 30.0
# Speed (in meters per second) at which waves move backward in spillback conditions.
# Comment to use instantaneous backward wave propagation.
# backward_wave_speed = 4.0
# Routing algorithm to use in METROPOLIS (Intersect or TCH).
routing_algorithm = "Intersect"
# Headway of car vehicles.
car_headway = 8.0
# PCE of car vehicles.
car_pce = 1.0
# Headway of truck vehicles.
truck_headway = 16.0
# PCE of truck vehicles.
truck_pce = 2.0
# Maximum speed for truck vehicles (in km/h).
truck_speed_limit = 90.0
# Whether vehicles are allowed to overtake vehicles pending to take a different outgoing edge.
overtaking = true
# Whether bottleneck congestion should be enabled (capacities must be specified).
use_bottleneck = true
# Walking speed in km/h.
walking_speed = 4.0
# Bicycle speed in km/h.
bicycle_speed = 10.0

[run.road_only]
# Directory where the files for the road-only run are stored.
directory = "./run/road_only5/"
# Value of the smoothing factor for the learning model (weight of the simulated travel times).
smoothing_factor = 0.05
# Number of iterations to run.
nb_iterations = 20
# If `true`, the network conditions from the previous run are used.
reuse_net_cond = false

[run.road_only_same_route]
# Directory where the files for the road-only run are stored.
directory = "./run/road_only_same_route_2a/"

[run.tomtom_routes]
# Directory where the files for the TomTom-routes run are stored.
directory = "./run/tomtom_routes/"

[osm]
# Path to the .osm.pbf file to use as input.
input_file = "./data/ile-de-france-240101.osm.pbf"
# Whether statistics on the imported network should be printed.
print_stats = true
# Whether graphs of the variables should be saved.
output_graphs = true
# OpenStreetMap's highway tags to import.
# See https://wiki.openstreetmap.org/wiki/Key:highway
highways = [
  "motorway",
  "motorway_link",
  "trunk",
  "trunk_link",
  "primary",
  "primary_link",
  "secondary",
  "secondary_link",
  "tertiary",
  "tertiary_link",
  "living_street",
  "unclassified",
  "residential",
  #"road",
  #"service",
]
# Array of OpenStreetMap's landuse tags to be considered as urban areas.
# See https://wiki.openstreetmap.org/wiki/Key:landuse
urban_landuse = [
  "commercial",
  "construction",
  "education",
  "industrial",
  "residential",
  "retail",
  #"grass",
  #"cemetery",
  #"basin",
  #"allotments",
  "village_green",
  #"flowerbed",
  "recreation_ground",
  "military",
  "garages",
  "religious",
]


[postprocess_network]
# Minimum number of lanes allowed on edges.
min_nb_lanes = 0.5
# Minimum speed limit allowed on edges (in km/h).
min_speed_limit = 10
# Minimum length allowed on edges (in meters).
min_length = 1
# Whether the duplicate edges (edges with same source and target) should be removed.
# Only the edge with the smallest free-flow travel time is kept.
remove_duplicates = false
# Whether the network should be restricted to the largest strongly connected component of the
# underlying graph.
# Warning. If `false`, some origin-destination pairs might not be feasible.
ensure_connected = true
# If `true`, the edges are re-index after the postprocessing so that they are indexed from 0 to n-1.
reindex = false
# Whether statistics on the network should be printed.
print_stats = true
# Whether graphs of the variables should be saved.
output_graphs = true

# Default speed limit per roadtype, in km/h, in rural areas.
[postprocess_network.default_speed_limit.rural]
motorway = 130
trunk = 110
primary = 80
secondary = 80
tertiary = 70
motorway_link = 70
trunk_link = 50
primary_link = 50
secondary_link = 50
tertiary_link = 50
living_street = 20
unclassified = 50
residential = 50
#road = 20
#service = 20

# Default speed limit per roadtype, in km/h, in urban areas.
[postprocess_network.default_speed_limit.urban]
motorway = 130
trunk = 90
primary = 50
secondary = 50
tertiary = 30
motorway_link = 50
trunk_link = 50
primary_link = 50
secondary_link = 50
tertiary_link = 30
living_street = 20
unclassified = 30
residential = 30
#road = 20
#service = 20

# Default number of lanes per roadtype.
[postprocess_network.default_nb_lanes]
motorway = 3
trunk = 2
primary = 1
secondary = 1
tertiary = 1
motorway_link = 1
trunk_link = 1
primary_link = 1
secondary_link = 1
tertiary_link = 1
living_street = 1
unclassified = 1
residential = 1
#road = 1
#service = 1

[road_network.restriction_area]
# Path to the GeoDataFrame file with the definition of the restriction area.
# If the GeoDataFrame has more than one row, the unary of the geometries is taken.
area_filename = "./data/lez/lez.geojson"
# Path to the output filename which stores the indicator inside / outside the area for all edges.
output_filename = "./output/road_network/edges_lez.parquet"

[osm_walk]
# Path to the .osm.pbf file to use as input.
input_file = "./data/ile-de-france-240101.osm.pbf"
# Whether statistics on the imported network should be printed.
print_stats = true
# Whether graphs of the variables should be saved.
output_graphs = true
# OpenStreetMap's highway tags to import.
# See https://wiki.openstreetmap.org/wiki/Key:highway
highways = [
  #"motorway",
  #"motorway_link",
  "trunk",
  "trunk_link",
  "primary",
  "primary_link",
  "secondary",
  "secondary_link",
  "tertiary",
  "tertiary_link",
  "living_street",
  "unclassified",
  "residential",
  "road",
  "service",
  "track",
  "footway",
  "path",
  "pedestrian",
]

[postprocess_network_walk]
# Minimum length allowed on edges (in meters).
min_length = 1
# Whether the duplicate edges (edges with same source and target) should be removed.
# Only the edge with the smallest free-flow travel time is kept.
remove_duplicates = false
# Whether the network should be restricted to the largest strongly connected component of the
# underlying graph.
# Warning. If `false`, some origin-destination pairs might not be feasible.
ensure_connected = true
# If `true`, the edges are re-index after the postprocessing so that they are indexed from 0 to n-1.
reindex = false
# Whether statistics on the network should be printed.
print_stats = true
# Whether graphs of the variables should be saved.
output_graphs = true

[synthetic_population]
# Path to the output directory of the synthetic population pipeline.
input_directory = "eqasim_output/"
# Name of the generated synthetic population.
# This is the prefix used in the output files.
name = "ile_de_france"
# If `true`, a `tour_id` column will be created with unique identifier for the home-to-home tours of the persons.
# This will remove the persons who do not start or do not end at their home place.
identify_tours = true

[synthetic_population.french_vehicle_fleet]
# Path to the CSV file with the French vehicle fleet data at the INSEE commune level.
# https://www.statistiques.developpement-durable.gouv.fr/catalogue?page=dataset&datasetId=64511438f3196b5b550dd093
fleet_filename = "./data/parc/Donnees-sur-le-parc-de-vehicule-au-niveau-communal.2023-05.csv"
# Year of the vehicle fleet to be used.
fleet_year = 2022
# Path to the output file where the household vehicles are stored.
output_filename = "./output/synthetic_population_20pct/vehicles.parquet"
# Optional file representing transition probabilities from one critair to another.
evolution_matrix = "./data/parc/evolution_matrix.parquet"

[synthetic_population.french_vehicle_fleet.car_types]
# Conversion from fuel type + Crit'Air to European emission standard.
# https://en.wikipedia.org/wiki/European_emission_standards
essence.critair_1 = "PC_petrol_euro_5_6"
essence.critair_2 = "PC_petrol_euro_4"
essence.critair_3 = "PC_petrol_euro_2_3"
essence.non_classe = "PC_petrol_euro_1"
essence_hnr.critair_1 = "PC_petrol_euro_5_6"
essence_hnr.critair_2 = "PC_petrol_euro_4"
essence_hnr.critair_3 = "PC_petrol_euro_2_3"
diesel.critair_2 = "PC_diesel_euro_5_6"
diesel.critair_3 = "PC_diesel_euro_4"
diesel.critair_4 = "PC_diesel_euro_3"
diesel.critair_5 = "PC_diesel_euro_2"
diesel.non_classe = "PC_diesel_euro_1"
diesel_hnr.critair_2 = "PC_diesel_euro_5_6"
hybride_rechargeable.critair_1 = "PC_hybrid_petrol"
hybride_rechargeable.critair_2 = "PC_hybrid_petrol"
electrique_et_hydrogene.critair_e = "PC_electric"
electrique_et_hydrogene.non_classe = "PC_electric"
gaz_et_inconnu.critair_1 = "PC_electric"
gaz_et_inconnu.critair_2 = "PC_electric"
gaz_et_inconnu.critair_3 = "PC_electric"
gaz_et_inconnu.non_classe = "PC_electric"

[synthetic_population.plot]
household_id = 19
filename = "./output/synthetic_population/household_19.html"

[france]
# Path to the ADMIN-EXPRESS shapefile with the INSEE communes geometries.
insee_filename = "./data/ADMIN-EXPRESS/1_DONNEES_LIVRAISON_2023-07-04/ADE_3-2_SHP_LAMB93_FXX/COMMUNE.shp"
# Path to the ADMIN-EXPRESS shapefile with the INSEE arrondissements geometries.
arrondissement_filename = "./data/ADMIN-EXPRESS/1_DONNEES_LIVRAISON_2023-07-04/ADE_3-2_SHP_LAMB93_FXX/ARRONDISSEMENT_MUNICIPAL.shp"
# Path to the shapefile with the IRIS geometries.
iris_filename = "./data/contours_iris_france/CONTOURS-IRIS.shp"

[od_matrix]
# Path to the shapefile with the zoning geometries.
# The file must have columns `zone_id` and `geometry`.
zone_filename = "./data/zonage_modus/zones_modus.parquet"
# Path to the OD matrix.
# The file must have columns `origin`, `destination` and `count`.
# Extensions: CSV, Parquet.
od_matrix_filename = "./data/od_matrix/od_matrix_modus_ref.parquet"
# Maximum number of unique nodes that can be selected as origin / destination in each zone.
# Comment to allow unlimited number of unique nodes.
# max_nb_nodes_per_zone = 100

[od_matrix.weights.rural]
motorway = 0
trunk = 0
primary = 1
secondary = 1
tertiary = 1
motorway_link = 0
trunk_link = 0
primary_link = 1
secondary_link = 1
tertiary_link = 1
living_street = 8
unclassified = 1
residential = 4

[od_matrix.weights.urban]
motorway = 0
trunk = 0
primary = 24
secondary = 22
tertiary = 19
motorway_link = 0
trunk_link = 0
primary_link = 11
secondary_link = 9
tertiary_link = 7
living_street = 35
unclassified = 13
residential = 18

[calibration.tomtom]
# Path to the output file where the TomTom requests results are stored
# (possible extensions: parquet, geojson, fgb, shp).
output_filename = "./output/calibration/tomtom_results.parquet"
# Departure time to be used for the requests.
# Format: "yyyy-mm-ddTHH:MM:SS"
departure_time = "2024-11-25T03:00:00"
# Number of routes to request.
# Note. Free TomTom API is limiting the daily number of requests to 2500.
nb_routes = 2000
# Number of waypoints to use for each route request.
# Note. The number of OD pairs per route is equal to the number of waypoints minus 1 so that the
# total number of OD pairs is equal to `nb_routes * nb_waypoints - 1`.
# Note. TomTom API is limiting the number of waypoints to 150.
nb_waypoints = 150
# Number of batches to be computed in parallel.
# Ideally, the value should be the number of threads that you want to use.
# If the value is too large, TomTom API might complain about exceeding the number of requests per second.
nb_batches = 2
# Road types which cannot be selected as origin or destination node for the OD pairs.
# The edges whose `road_type` column value is equal to one of the given road type will be excluded
# from the road network prior to selecting the origin and destination nodes.
excluded_road_types = ["motorway", "motorway_link", "trunk", "trunk_link"]

[calibration.map_matching]
# Path to the output file where the map matching results are stored.
# (possible extensions: parquet).
output_filename = "./output/calibration/match_results.parquet"
# Search radius, in meters.
# Larger values are more likely to result in a positive match but increase running time.
# Recommended value: between 30 and 200.
radius = 100
# Maximum relative length difference allowed between TomTom routes and road-network routes.
# A value of 0.01 means that routes for which the length of the matched path on the road-network
# differs by more than 1% compared to the length of the TomTom path will be excluded.
rel_length_threshold = 0.005

[calibration.variables]
# Variables that can be used in the regression of calibration together with their type.
# Four options (that can be combined):
# - `var = true`: The modalities will be `true` and `false`. The variable needs to be of boolean type.
# - `var = [a, b, c]`: The modalities will be (-infinity, a], (a, b], (b, c], (c, +infinity).
#   The modalities with no observation are not created. The variable needs to be of numeric type.
# - `var = x`: The modalities will be 0, 1, 2, ..., x, [x, +infinity). The modalities with no
#   observation are not created. The variable needs to be of integer type.
# - Table `calibration.variables.var` of `key = value`. The modalities will consist in all values
#   given. The variable needs to be of categorical type, all unique values need to be set as a key.
urban = true
roundabout = true
traffic_signals = true
stop_sign = true
give_way_sign = true
speed_limit = [30.0, 50.0, 70.0, 80.0, 90.0, 110.0, 130.0]
lanes = [1.0, 2.0, 3.0]
target_incomings = 4
source_incomings = 4
target_outgoings = 4
source_outgoings = 4

[calibration.variables.road_type]
unclassified = "unclassified"
#road = "unclassified"
residential = "residential"
#service = "residential"
living_street = "living_street"
tertiary = "tertiary"
tertiary_link = "tertiary"
secondary = "secondary"
secondary_link = "secondary"
primary_link = "primary_link"
primary = "primary"
trunk = "trunk"
trunk_link = "trunk_link"
motorway_link = "motorway_link"
motorway = "motorway"

[calibration.free_flow_calibration]
# Path to the output file where the LASSO coefficients are stored
# (possible extensions: Parquet, CSV).
coef_filename = "./output/calibration/free_flow_lasso_coef.parquet"
# List of variables to be used additively in the regression.
additive_variables = ["traffic_signals"]
# List of interaction variables to be used additively in the regression.
additive_interaction_variables = [["urban", "traffic_signals"]]
# List of variables to be used additively in the regression.
multiplicative_variables = ["road_type", "speed_limit"]
# List of interaction variables to be used additively in the regression.
multiplicative_interaction_variables = [
  [
    "road_type",
    "speed_limit",
  ],
  [
    "urban",
    "speed_limit",
  ],
  [
    "speed_limit",
    "target_incomings",
  ],
  [
    "speed_limit",
    "target_outgoings",
  ],
  [
    "target_incomings",
    "target_outgoings",
  ],
]
# List of alpha penalties to try in the LASSO regression.
alphas = [1, 5, 10]

[calibration.edge_penalties]
# Path to the output file where the edge penalties are stored
# (possible extensions: Parquet, CSV).
output_filename = "./output/road_network/edges_penalties.parquet"
# Lower bound for the additive penalty.
additive_penalty_lower_bound = 0
# Lower bound for the road speed on an edge (in km/h).
road_speed_lower_bound = 10
# Upper bound for the global speed on an edge (in km/h).
global_speed_upper_bound = 140
# If `true`, create graphs comparing the free-flow travel time in TomTom and in the simulation.
plot_graphs = true

[calibration.capacities_calibration]
# List of variables to be used in the regression.
explanatory_variables = ["road_type", "roundabout", "traffic_signals", "lanes"]
# explanatory_variables = ["road_type", "traffic_signals"]
# List of interaction variables to be used in the regression.
# interaction_variables = [["road_type", "speed_limit"], ["urban", "speed_limit"]]
# interaction_variables = [["road_type", "traffic_signals"]]
interaction_variables = []
# List of alpha penalties to try in the LASSO regression.
# alphas = [5, 10, 100, 200, 500]
# Maximum capacity (in PCE / h) that is allowed on edges.
maximum_capacity = 2200

[calibration.departure_time_calibration]
# Directory where the simulations are run.
run_directory = "./run/departure_time_calibration/"

[calibration.mode_calibration]
# Directory where the simulations are run.
run_directory = "./run/mode_calibration/"

[travel_survey]
# Path to the directory where the travel survey is stored.
directory = "./data/travel_survey/egt/"
# Type of travel survey.
# Possible values: "EGT".
survey_type = "EGT"

[travel_survey.desired_times]
# Path to the file with the probabilities of desired start time and duration for work activities.
desired_work_times_filename = "./output/travel_survey/desired_work_times.parquet"

[travel_survey.draw_tstars]
# Path to the file with the tstar probabilities.
tstars_probs_filename = "./output/travel_survey/tstars_probs.parquet"

[travel_survey.departure_time_distribution]
# Path to the file with the departure time distributions.
distribution_filename = "./output/travel_survey/departure_time_distributions.parquet"
# Path to the file with the centers of the clusters.
cluster_filename = "./output/travel_survey/departure_time_cluster_centers.parquet"

[travel_survey.mode_shares]
# Path to the file with the mode shares.
mode_shares_filename = "./output/travel_survey/mode_shares.parquet"
# Path to the file with the centers of the clusters.
cluster_filename = "./output/travel_survey/mode_cluster_centers.parquet"

[routing.opentripplanner]
# Base URL of the OpenTripPlanner server instance.
url = "http://0.0.0.0:8080/otp/gtfs/v1"
# Path to the output file where the public-transit travel times and itineraries are stored
# (possible extensions: Parquet, CSV).
output_filename = "./output/routing/pt_travel_times.parquet"
# Date to be used for the requests (format: yyyy-mm-dd).
date = "2024-05-21"
# If "departure": the trips' column "departure_time" is read and use as departure time for the requests.
# If "arrival": the trips' column "arrival_time" is read and use as arrival time for the requests.
# If "tstar": the trips' column "tstar" is read and use as arrival time for the requests.
# Otherwise, this must be a string "hh:mm:ss" specifying the departure time for the requests
# (e.g., "08:00:00" for 8 a.m.).
time = "arrival"
# Number of threads to use to parallelize the computation.
nb_threads = 8
# Optionally, the requests can be run in batches to reduce memory use.
# Set this to the number of trips in each batch, or comment to run a single batch.
batch_size = 200000

[public_transit.analyze_flows]
# Path to the GTFS zipfile.
gtfs_zipfile = "./data/IDFM-gtfs.zip"
# Path to the output file with the public-transit flows
# (possible extensions: parquet, geojson, fgb, shp).
output_filename = "./output/public_transit/flows_main.parquet"
# If `true`, the public-transit flows are computed for all flows, not only the agents who took public transit.
all_flows = false

[public_transit.chevelus]
# Path to the GTFS zipfile.
gtfs_zipfile = "./data/IDFM-gtfs.zip"
# Id of the route to be selected.
route_id = "GPE:18"
# Id of the start stop to be selected.
from_stop_id = "GA47"
# Id of the end stop to be selected.
to_stop_id = "GA48"
# Path to the output file with the chevelus
# (possible extensions: parquet, geojson, fgb, shp).
output_filename = "./output/public_transit/chevelus.parquet"

[routing.walking_distance]
# Path to the output file where the walking distances are stored
# (possible extensions: Parquet, CSV).
output_filename = "./output/routing/walking_distances.parquet"
# Whether graphs of the variables should be saved.
output_graphs = true
# Optional list of highway tags to be excluded from the list of potential origin / destination edges.
forbidden_road_types = ["motorway", "motorway_link", "trunk", "trunk_link"]

[routing.road_split]
# List of road type values that should be part of the main road-network graph.
main_road_types = [
  "motorway",
  "motorway_link",
  "trunk",
  "trunk_link",
  "primary",
  "primary_link",
  "secondary",
  "secondary_link",
  "tertiary",
  "tertiary_link",
  # "living_street",
  # "unclassified",
  # "residential",
  # "road",
  # "service",
]
# Path to the output file where the road split details are stored
# (possible extensions: Parquet, CSV).
trips_filename = "./output/routing/road_split.parquet"
# Path to the output file where the main status of edges is sorted
# (possible extensions: Parquet, CSV).
main_edges_filename = "./output/road_network/edges_main.parquet"
# Whether graphs of the variables should be saved.
output_graphs = true
# Optional list of highway tags to be excluded from the list of potential origin / destination edges.
forbidden_road_types = ["motorway", "motorway_link", "trunk", "trunk_link"]
# Optional list of highway tags to be excluded from the list of potential origin / destination edges, for trucks.
truck_forbidden_road_types = ["living_street", "residential"]

[road_results.edge_values]
# Path to the output file with the edge-level values
# (possible extensions: parquet, csv).
output_filename = "./output/road_results/edge_values.parquet"

[road_results.chevelus]
# Id of the route to be selected.
edge_id = 1
# Path to the output file with the chevelus
# (possible extensions: parquet, geojson, fgb, shp).
output_filename = "./output/road_results/chevelus.parquet"

[emisens]
# Path to the CSV file with emission factors.
# For now, the only supported format is CSV or Parquet with columns `car_type` (European emission
# standard), `pollutant` ("CO", "NOx", "PM" or "EC") and `[hot|cold]_[0-9]*-[0-9]*` (emission factor
# for cold or hot emissions, with speed interval).
emission_factor_file = "./data/emission_factors_france.csv"
# List of pollutants to be computed.
# Possible values: "CO", "NOx", "PM", "EC".
# Specify "EC" (energy consumption) to also compute CO2 and fuel consumption.
pollutants = ["NOx", "PM", "EC"]
# Threshold of distance traveled (in kilometers) for cold emissions.
cold_emissions_threshold = 11.33
# Interval of time (in seconds) to split emissions.
interval = 360_000
# Path to the output file where the trip-level emissions are stored
# (possible extensions: Parquet, CSV).
trip_emissions = "./output/emissions/trip_emissions.parquet"
# Path to the output file where the edge-level emissions are stored
# (possible extensions: Parquet, CSV).
edge_emissions = "./output/emissions/edge_emissions.parquet"

[metro-trace]
# Height and width of one cell of the grid used for pollution concentration and exposition (in meters).
grid_resolution = 500
# Filename where the gridded emissions are stored.
gridded_emissions_filename = "./output/emissions/gridded_emissions.parquet"
# Filename where the pollutant concentrations are stored.
concentration_filename = "./output/emissions/concentrations.parquet"
# Filename where the population dispersion is stored.
population_dispersion_filename = "./output/emissions/population_dispersion.parquet"
# Filename where the population exposure is stored.
exposure_filename = "./output/emissions/exposure.parquet"
# Average number of years lost for someone dying from air pollution.
average_years_lost = 10.4
# Price of a year of life lost.
year_of_life_lost_price = 106_985

[metro-trace.exposure_probs]
# Probability of dying when being exposed to some quantity of pollutants (expressed in μg / m3 / h).
NO2 = 6.224812e-10
PM = 5.077455e-9

[fuel_consumption]
# Path to the output file where the fuel consumptions are stored.
output_filename = "./output/emissions/ff_fuel_consumption2.parquet"

[demand]
# List of modes in the simulations.
# modes = ["car_driver", "car_passenger", "motorcycle", "public_transit", "bicycle", "walking"]
modes = ["car_driver", "car_passenger", "public_transit", "bicycle", "walking"]

[demand.predict_modes]
output_graphs = true

[demand.epsilons]
# List of mode nests.
nests = [
    ["car_driver", "car_passenger", "motorcycle"],
    ["public_transit"],
    ["bicycle", "walking"],
]
# Lambda value per nest.
lambdas = [1.0, 1.0, 1.0]
# Scale of the Gumbel epsilons.
mu = 1.0
