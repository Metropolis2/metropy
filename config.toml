# Projected coordinate system to use for metric operations (e.g., computing edges' length).
# See: https://en.wikipedia.org/wiki/Projected_coordinate_system
crs = "EPSG:2154"

# Random seed to be used for random number generators.
random_seed = 13081996

# Path to the directory where graphs should be stored.
graph_directory = "./output/graph/"

# Path to METROPOLIS2's routing executable.
routing_exec = "./execs/routing_cli"

# Directory to be used to temporarily store files.
tmp_directory = "./tmp/"

# Directory where the run input / output are stored.
run_directory = "./run/road_only"

# Path to the file where the imported edges of the road network are stored
# (possible extensions: parquet, geojson, fgb, shp).
raw_edges_file = "./output/road_network/edges_raw.parquet"
# Path to the file where the imported edges of the road network are stored after the cleaning
# process (possible extensions: parquet, geojson, fgb, shp).
clean_edges_file = "./output/road_network/edges_clean.parquet"

# Path to the file where the imported edges of the walking road network are stored
# (possible extensions: parquet, geojson, fgb, shp).
raw_walk_edges_file = "./output/road_network/edges_walk_raw.parquet"
# Path to the file where the imported edges of the walking road network are stored after the
# cleaning process (possible extensions: parquet, geojson, fgb, shp).
clean_walk_edges_file = "./output/road_network/edges_walk_clean.parquet"

# Path to the directory where the population files are stored.
population_directory = "./output/synthetic_population_20pct/"

[run]
# Directory where the run files are stored.
directory = "./run/main/"
# Format to use for the input and output files ("CSV" or "Parquet").
format = "Parquet"
# Ratio of population that is simulated.
simulation_ratio = 0.2
# Ratio of truck trips simulated.
truck_simulation_ratio = 1.0
# Simulation period.
period = [10_800, 97_200]
# Time interval between two breakpoints in the travel-time functions (in seconds).
recording_interval = 900.0
# Value of the smoothing factor for the learning model (weight of the simulated travel times).
smoothing_factor = 0.02
# Whether spillback is enabled.
spillback = true
# Maximum amount of time (in seconds) a vehicle can be pending to enter the next edge.
max_pending_duration = 30.0
# Speed (in meters per second) at which waves move backward in spillback conditions.
# Comment to use instantaneous backward wave propagation.
backward_wave_speed = 4.0
# Routing algorithm to use in METROPOLIS (Intersect or TCH).
routing_algorithm = "Intersect"
# Headway of car vehicles.
car_headway = 8.0
# PCE of car vehicles.
car_pce = 1.0
# Headway of truck vehicles.
truck_headway = 16.0
# PCE of truck vehicles.
truck_pce = 2.0
# Maximum speed for truck vehicles (in km/h).
truck_speed_limit = 90.0
# Whether vehicles are allowed to overtake vehicles pending to take a different outgoing edge.
overtaking = true
# Whether bottleneck congestion should be enabled (capacities must be specified).
bottleneck = true

[run.edge_capacity]
# Bottleneck capacity per roadtype, in PCE/h.
motorway = 2000
trunk = 2000
primary = 1500
secondary = 800
tertiary = 600
motorway_link = 1500
trunk_link = 1500
primary_link = 1500
secondary_link = 800
tertiary_link = 600
living_street = 300
unclassified = 600
residential = 600
#road = 300
#service = 300

[run.road_only]
# Directory where the files for the road-only run are stored.
directory = "./run/road_only/"
# Value of the smoothing factor for the learning model (weight of the simulated travel times).
smoothing_factor = 0.02
# Number of iterations to run.
nb_iterations = 100

[run.tomtom_routes]
# Directory where the files for the TomTom-routes run are stored.
directory = "./run/tomtom_routes/"

[osm]
# Path to the .osm.pbf file to use as input.
input_file = "./data/ile-de-france-240101.osm.pbf"
# Whether statistics on the imported network should be printed.
print_stats = true
# Whether graphs of the variables should be saved.
output_graphs = true
# OpenStreetMap's highway tags to import.
# See https://wiki.openstreetmap.org/wiki/Key:highway
highways = [
  "motorway",
  "motorway_link",
  "trunk",
  "trunk_link",
  "primary",
  "primary_link",
  "secondary",
  "secondary_link",
  "tertiary",
  "tertiary_link",
  "living_street",
  "unclassified",
  "residential",
  #"road",
  #"service",
]
# Array of OpenStreetMap's landuse tags to be considered as urban areas.
# See https://wiki.openstreetmap.org/wiki/Key:landuse
urban_landuse = [
  "commercial",
  "construction",
  "education",
  "industrial",
  "residential",
  "retail",
  #"grass",
  #"cemetery",
  #"basin",
  #"allotments",
  "village_green",
  #"flowerbed",
  "recreation_ground",
  "military",
  "garages",
  "religious",
]


[postprocess_network]
# Minimum number of lanes allowed on edges.
min_nb_lanes = 0.5
# Minimum speed limit allowed on edges (in km/h).
min_speed_limit = 10
# Minimum length allowed on edges (in meters).
min_length = 1
# Whether the duplicate edges (edges with same source and target) should be removed.
# Only the edge with the smallest free-flow travel time is kept.
remove_duplicates = false
# Whether the network should be restricted to the largest strongly connected component of the
# underlying graph.
# Warning. If `false`, some origin-destination pairs might not be feasible.
ensure_connected = true
# If `true`, the edges are re-index after the postprocessing so that they are indexed from 0 to n-1.
reindex = false
# Whether statistics on the network should be printed.
print_stats = true
# Whether graphs of the variables should be saved.
output_graphs = true

# Default speed limit per roadtype, in km/h, in rural areas.
[postprocess_network.default_speed_limit.rural]
motorway = 130
trunk = 110
primary = 80
secondary = 80
tertiary = 70
motorway_link = 70
trunk_link = 50
primary_link = 50
secondary_link = 50
tertiary_link = 50
living_street = 20
unclassified = 50
residential = 50
#road = 20
#service = 20

# Default speed limit per roadtype, in km/h, in urban areas.
[postprocess_network.default_speed_limit.urban]
motorway = 130
trunk = 90
primary = 50
secondary = 50
tertiary = 30
motorway_link = 50
trunk_link = 50
primary_link = 50
secondary_link = 50
tertiary_link = 30
living_street = 20
unclassified = 30
residential = 30
#road = 20
#service = 20

# Default number of lanes per roadtype.
[postprocess_network.default_nb_lanes]
motorway = 3
trunk = 2
primary = 1
secondary = 1
tertiary = 1
motorway_link = 1
trunk_link = 1
primary_link = 1
secondary_link = 1
tertiary_link = 1
living_street = 1
unclassified = 1
residential = 1
#road = 1
#service = 1

[road_network.restriction_area]
# Path to the GeoDataFrame file with the definition of the restriction area.
# If the GeoDataFrame has more than one row, the unary of the geometries is taken.
area_filename = "./data/lez/lez.geojson"
# Path to the output filename which stores the indicator inside / outside the area for all edges.
output_filename = "./output/road_network/edges_lez.parquet"

[osm_walk]
# Path to the .osm.pbf file to use as input.
input_file = "./data/ile-de-france-240101.osm.pbf"
# Whether statistics on the imported network should be printed.
print_stats = true
# Whether graphs of the variables should be saved.
output_graphs = true
# OpenStreetMap's highway tags to import.
# See https://wiki.openstreetmap.org/wiki/Key:highway
highways = [
  #"motorway",
  #"motorway_link",
  "trunk",
  "trunk_link",
  "primary",
  "primary_link",
  "secondary",
  "secondary_link",
  "tertiary",
  "tertiary_link",
  "living_street",
  "unclassified",
  "residential",
  "road",
  "service",
  "track",
  "footway",
  "path",
  "pedestrian",
]

[postprocess_network_walk]
# Minimum length allowed on edges (in meters).
min_length = 1
# Whether the duplicate edges (edges with same source and target) should be removed.
# Only the edge with the smallest free-flow travel time is kept.
remove_duplicates = false
# Whether the network should be restricted to the largest strongly connected component of the
# underlying graph.
# Warning. If `false`, some origin-destination pairs might not be feasible.
ensure_connected = true
# If `true`, the edges are re-index after the postprocessing so that they are indexed from 0 to n-1.
reindex = false
# Whether statistics on the network should be printed.
print_stats = true
# Whether graphs of the variables should be saved.
output_graphs = true

[synthetic_population]
# Path to the output directory of the synthetic population pipeline.
input_directory = "eqasim_output/"
# Name of the generated synthetic population.
# This is the prefix used in the output files.
name = "ile_de_france"
# If `true`, a `tour_id` column will be created with unique identifier for the home-to-home tours of the persons.
# This will remove the persons who do not start or do not end at their home place.
identify_tours = true

[synthetic_population.french_vehicle_fleet]
# Path to the CSV file with the French vehicle fleet data at the INSEE commune level.
fleet_filename = "./data/parc/Donnees-sur-le-parc-de-vehicule-au-niveau-communal.2023-05.csv"
# Year of the vehicle fleet to be used.
fleet_year = 2022
# Path to the output file where the household vehicles are stored.
output_filename = "./output/synthetic_population/vehicles.parquet"

[synthetic_population.french_vehicle_fleet.car_types]
# Conversion from fuel type + Crit'Air to European emission standard.
# https://en.wikipedia.org/wiki/European_emission_standards
essence.critair_1 = "PC_petrol_euro_5_6"
essence.critair_2 = "PC_petrol_euro_4"
essence.critair_3 = "PC_petrol_euro_2_3"
essence.non_classe = "PC_petrol_euro_1"
essence_hnr.critair_1 = "PC_petrol_euro_5_6"
essence_hnr.critair_2 = "PC_petrol_euro_4"
essence_hnr.critair_3 = "PC_petrol_euro_2_3"
diesel.critair_2 = "PC_diesel_euro_5_6"
diesel.critair_3 = "PC_diesel_euro_4"
diesel.critair_4 = "PC_diesel_euro_3"
diesel.critair_5 = "PC_diesel_euro_2"
diesel.non_classe = "PC_diesel_euro_1"
diesel_hnr.critair_2 = "PC_diesel_euro_5_6"
hybride_rechargeable.critair_1 = "PC_hybrid_petrol"
hybride_rechargeable.critair_2 = "PC_hybrid_petrol"
electrique_et_hydrogene.critair_e = "PC_electric"
electrique_et_hydrogene.non_classe = "PC_electric"
gaz_et_inconnu.critair_1 = "PC_electric"
gaz_et_inconnu.critair_2 = "PC_electric"
gaz_et_inconnu.critair_3 = "PC_electric"
gaz_et_inconnu.non_classe = "PC_electric"

[synthetic_population.predict_modes]
output_graphs = true

[synthetic_population.plot]
household_id = 19
filename = "./output/synthetic_population/household_19.html"

[france]
# Path to the ADMIN-EXPRESS shapefile with the INSEE communes geometries.
insee_filename = "./data/ADMIN-EXPRESS/1_DONNEES_LIVRAISON_2023-07-04/ADE_3-2_SHP_LAMB93_FXX/COMMUNE.shp"
# Path to the shapefile with the IRIS geometries.
iris_filename = "./data/contours_iris_france/CONTOURS-IRIS.shp"

[od_matrix]
# Path to the shapefile with the zoning geometries.
# The file must have columns `zone_id` and `geometry`.
zone_filename = "./data/zonage_modus/zones_modus.parquet"
# Path to the OD matrix.
# The file must have columns `origin`, `destination` and `count`.
# Extensions: CSV, Parquet.
od_matrix_filename = "./data/od_matrix/od_matrix_modus_ref.parquet"
# Maximum number of unique nodes that can be selected as origin / destination in each zone.
# Comment to allow unlimited number of unique nodes.
# max_nb_nodes_per_zone = 100

[od_matrix.weights.rural]
motorway = 0
trunk = 0
primary = 1
secondary = 1
tertiary = 1
motorway_link = 0
trunk_link = 0
primary_link = 1
secondary_link = 1
tertiary_link = 1
living_street = 8
unclassified = 1
residential = 4

[od_matrix.weights.urban]
motorway = 0
trunk = 0
primary = 24
secondary = 22
tertiary = 19
motorway_link = 0
trunk_link = 0
primary_link = 11
secondary_link = 9
tertiary_link = 7
living_street = 35
unclassified = 13
residential = 18

[calibration.tomtom]
# Path to the output file where the TomTom requests results are stored
# (possible extensions: parquet, geojson, fgb, shp).
output_filename = "./output/calibration/tomtom_results.parquet"
# Departure time to be used for the requests.
# Format: "yyyy-mm-ddTHH:MM:SS"
departure_time = "2024-11-25T03:00:00"
# Number of routes to request.
# Note. Free TomTom API is limiting the daily number of requests to 2500.
nb_routes = 2000
# Number of waypoints to use for each route request.
# Note. The number of OD pairs per route is equal to the number of waypoints minus 1 so that the
# total number of OD pairs is equal to `nb_routes * nb_waypoints - 1`.
# Note. TomTom API is limiting the number of waypoints to 150.
nb_waypoints = 150
# Number of batches to be computed in parallel.
# Ideally, the value should be the number of threads that you want to use.
# If the value is too large, TomTom API might complain about exceeding the number of requests per second.
nb_batches = 8
# Road types which cannot be selected as origin or destination node for the OD pairs.
# The edges whose `road_type` column value is equal to one of the given road type will be excluded
# from the road network prior to selecting the origin and destination nodes.
excluded_road_types = ["motorway", "motorway_link", "trunk", "trunk_link"]

[calibration.map_matching]
# Path to the output file where the map matching results are stored.
# This must be a CSV file.
output_filename = "./output/calibration/fmm_results.csv"
# Number of candidates to be considered as valid match.
# Larger values provide better match quality but increase running time.
# Recommended value: 8 or more.
nb_candidates = 20
# GPS error of the GPS points, in meters.
# The GPS points are the coordinates from the routing results.
# Recommended value: 5.
gps_error = 5
# Search radius, in meters.
# Larger values are more likely to result in a positive match but increase running time.
# Recommended value: between 30 and 200.
radius = 100

[calibration.post_map_matching]
# Path to the output file where the processed map matching results are stored
# (possible extensions: parquet).
output_filename = "./output/calibration/match_results.parquet"

[calibration.variables]
# Variables that can be used in the regression of calibration together with their type.
# Four options (that can be combined):
# - `var = true`: The modalities will be `true` and `false`. The variable needs to be of boolean type.
# - `var = [a, b, c]`: The modalities will be (-infinity, a], (a, b], (b, c], (c, +infinity).
#   The modalities with no observation are not created. The variable needs to be of numeric type.
# - `var = x`: The modalities will be 0, 1, 2, ..., x, [x, +infinity). The modalities with no
#   observation are not created. The variable needs to be of integer type.
# - Table `calibration.variables.var` of `key = value`. The modalities will consist in all values
#   given. The variable needs to be of categorical type, all unique values need to be set as a key.
urban = true
roundabout = true
traffic_signals = true
stop_sign = true
give_way_sign = true
speed_limit = [30.0, 50.0, 70.0, 80.0, 90.0, 110.0, 130.0]
lanes = [1.0, 2.0, 3.0]
target_incomings = 4
source_incomings = 4
target_outgoings = 4
source_outgoings = 4

[calibration.variables.road_type]
unclassified = "unclassified"
#road = "unclassified"
residential = "residential"
#service = "residential"
living_street = "living_street"
tertiary = "tertiary"
tertiary_link = "tertiary"
secondary = "secondary"
secondary_link = "secondary"
primary_link = "primary_link"
primary = "primary"
trunk = "trunk"
trunk_link = "trunk_link"
motorway_link = "motorway_link"
motorway = "motorway"

[calibration.free_flow_calibration]
# Path to the output file where the edge penalties are stored
# (possible extensions: Parquet, CSV).
output_filename = "./output/road_network/edges_penalties.parquet"
# Path to the output file where the LASSO coefficients are stored
# (possible extensions: Parquet, CSV).
coef_filename = "./output/calibration/free_flow_lasso_coef.parquet"
# List of variables to be used additively in the regression.
additive_variables = ["traffic_signals"]
# List of interaction variables to be used additively in the regression.
additive_interaction_variables = [["urban", "traffic_signals"]]
# List of variables to be used additively in the regression.
multiplicative_variables = ["road_type", "speed_limit"]
# List of interaction variables to be used additively in the regression.
multiplicative_interaction_variables = [
  [
    "road_type",
    "speed_limit",
  ],
  [
    "urban",
    "speed_limit",
  ],
  [
    "speed_limit",
    "target_incomings",
  ],
  [
    "speed_limit",
    "target_outgoings",
  ],
  [
    "target_incomings",
    "target_outgoings",
  ],
]
# List of alpha penalties to try in the LASSO regression.
alphas = [1, 5, 10]
# Lower bound for the additive penalty.
additive_penalty_lower_bound = 0
# Lower bound for the road speed on an edge (in km/h).
road_speed_lower_bound = 10
# Upper bound for the global speed on an edge (in km/h).
global_speed_upper_bound = 140

[calibration.capacities_calibration]
# List of variables to be used in the regression.
# explanatory_variables = ["road_type", "speed_limit", "urban", "roundabout", "traffic_signals", "stop_sign", "give_way_sign", "lanes", "target_incomings", "target_outgoings", "source_incomings", "source_outgoings"]
# explanatory_variables = ["road_type", "speed_limit", "roundabout", "lanes", "source_incomings"]
explanatory_variables = ["traffic_signals"]
# List of interaction variables to be used in the regression.
# interaction_variables = [["road_type", "speed_limit"], ["urban", "speed_limit"]]
# interaction_variables = [["road_type", "traffic_signals"]]
interaction_variables = []
# List of alpha penalties to try in the LASSO regression.
# alphas = [5, 10, 100, 200, 500]

[travel_survey]
# Path to the directory where the travel survey is stored.
directory = "./data/travel_survey/egt/"
# Type of travel survey.
# Possible values: "EGT".
survey_type = "EGT"

[routing.opentripplanner]
# Base URL of the OpenTripPlanner server instance.
url = "http://0.0.0.0:8080/otp/gtfs/v1"
# Path to the output file where the public-transit travel times and itineraries are stored
# (possible extensions: Parquet, CSV).
output_filename = "./output/routing/pt_travel_times.parquet"
# Date to be used for the requests (format: yyyy-mm-dd).
date = "2024-05-21"
# If "departure": the trips' column "departure_time" is read and use as departure time for the requests.
# If "arrival": the trips' column "arrival_time" is read and use as arrival time for the requests.
# If "tstar": the trips' column "tstar" is read and use as arrival time for the requests.
# Otherwise, this must be a string "hh:mm:ss" specifying the departure time for the requests
# (e.g., "08:00:00" for 8 a.m.).
time = "arrival"
# Number of threads to use to parallelize the computation.
nb_threads = 8
# Optionally, the requests can be run in batches to reduce memory use.
# Set this to the number of trips in each batch, or comment to run a single batch.
batch_size = 200000

[public_transit.analyze_flows]
# Path to the GTFS zipfile.
gtfs_zipfile = "./data/IDFM-gtfs.zip"
# Path to the output file with the public-transit flows
# (possible extensions: parquet, geojson, fgb, shp).
output_filename = "./output/public_transit/global_flows.parquet"
# If `true`, the public-transit flows are computed for all flows, not only the agents who took public transit.
all_flows = false

[public_transit.chevelus]
# Path to the GTFS zipfile.
gtfs_zipfile = "./data/IDFM-gtfs.zip"
# Id of the route to be selected.
route_id = "GPE:18"
# Id of the start stop to be selected.
from_stop_id = "GA47"
# Id of the end stop to be selected.
to_stop_id = "GA48"
# Path to the output file with the chevelus
# (possible extensions: parquet, geojson, fgb, shp).
output_filename = "./output/public_transit/chevelus.parquet"

[routing.walking_distance]
# Path to the output file where the walking distances are stored
# (possible extensions: Parquet, CSV).
output_filename = "./output/routing/walking_distances.parquet"
# Whether graphs of the variables should be saved.
output_graphs = true
# Optional list of highway tags to be excluded from the list of potential origin / destination edges.
forbidden_road_types = ["motorway", "motorway_link", "trunk", "trunk_link"]

[routing.road_split]
# List of road type values that should be part of the main road-network graph.
main_road_types = [
  "motorway",
  "motorway_link",
  "trunk",
  "trunk_link",
  "primary",
  "primary_link",
  "secondary",
  "secondary_link",
  "tertiary",
  "tertiary_link",
  # "living_street",
  # "unclassified",
  # "residential",
  # "road",
  # "service",
]
# Path to the output file where the road split details are stored
# (possible extensions: Parquet, CSV).
trips_filename = "./output/routing/road_split.parquet"
# Path to the output file where the main status of edges is sorted
# (possible extensions: Parquet, CSV).
main_edges_filename = "./output/road_network/edges_main.parquet"
# Whether graphs of the variables should be saved.
output_graphs = true
# Optional list of highway tags to be excluded from the list of potential origin / destination edges.
forbidden_road_types = ["motorway", "motorway_link", "trunk", "trunk_link"]
# Optional list of highway tags to be excluded from the list of potential origin / destination edges, for trucks.
truck_forbidden_road_types = ["living_street", "residential"]

[road_results.edge_values]
# Path to the output file with the edge-level values
# (possible extensions: parquet, csv).
output_filename = "./output/road_results/edge_values.parquet"

[road_results.chevelus]
# Id of the route to be selected.
edge_id = 1
# Path to the output file with the chevelus
# (possible extensions: parquet, geojson, fgb, shp).
output_filename = "./output/road_results/chevelus.parquet"

[emisens]
# Path to the CSV file with emission factors.
# For now, the only supported format is CSV or Parquet with columns `car_type` (European emission
# standard), `pollutant` ("CO", "NOx", "PM" or "EC") and `[hot|cold]_[0-9]*-[0-9]*` (emission factor
# for cold or hot emissions, with speed interval).
emission_factor_file = "./data/emission_factors_france.csv"
# List of pollutants to be computed.
# Possible values: "CO", "NOx", "PM", "EC".
# Specify "EC" (energy consumption) to also compute CO2 and fuel consumption.
pollutants = ["CO", "NOx", "PM", "EC"]
# Threshold of distance traveled (in kilometers) for cold emissions.
cold_emissions_threshold = 11.33
# Path to the output file where the emissions are stored
# (possible extensions: Parquet, CSV).
output_filename = "./output/emissions/emissions.parquet"
